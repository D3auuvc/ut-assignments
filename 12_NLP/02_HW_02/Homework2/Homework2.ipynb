{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\".\n",
    "\n",
    "__Also, please write how much time it took you to finish the homework.__ This will not affect your grade in any way and is used for statistical purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_SPENT = \"00h00m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "### Text Representations & Classification\n",
    "\n",
    "Welcome to Homework 2! \n",
    "\n",
    "The homework contains several tasks. You can find the amount of points that you get for the correct solution in the task header. Maximum amount of points for each homework is _four_.\n",
    "\n",
    "The **grading** for each task is the following:\n",
    "- correct answer - **full points**\n",
    "- insufficient solution or solution resulting in the incorrect output - **half points**\n",
    "- no answer or completely wrong solution - **no points**\n",
    "\n",
    "Even if you don't know how to solve the task, we encourage you to write down your thoughts and progress and try to address the issues that stop you from completing the task.\n",
    "\n",
    "When working on the written tasks, try to make your answers short and accurate. Most of the times, it is possible to answer the question in 1-3 sentences.\n",
    "\n",
    "When writing code, make it readable. Choose appropriate names for your variables (`a = 'cat'` - not good, `word = 'cat'` - good). Avoid constructing lines of code longer than 100 characters (79 characters is ideal). If needed, provide the commentaries for your code, however, a good code should be easily readable without them :)\n",
    "\n",
    "Finally, all your answers should be written only by yourself. If you copy them from other sources it will be considered as an academic fraud. You can discuss the tasks with your classmates but each solution must be individual.\n",
    "\n",
    "<font color='red'>**Important!:**</font> **before sending your solution, do the `Kernel -> Restart & Run All` to ensure that all your code works.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Read and preprocess the data (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Homework, you are going to use [IMDB movie reviews dataset](https://ai.stanford.edu/~amaas/data/sentiment/). It contains 50,000 reviews, from which 25,000 are labeled as \"positive\" and the other 25,000 as \"negative\". This dataset is very frequently used for benchmarking the binary classification models.\n",
    "\n",
    "For your convenience, the dataset is transformed into the .csv format and split into three files, each containing the train, validation, and test data accordingly. The labels are transformed into the binary format with `1` for \"positive\" and `0` for \"negative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(Path(\"imdb_dataset/Train.csv\"))\n",
    "data_val = pd.read_csv(Path(\"imdb_dataset/Valid.csv\"))\n",
    "data_test = pd.read_csv(Path(\"imdb_dataset/Test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your preprocessing function should minimally:\n",
    "- tokenize each text\n",
    "- lowercase\n",
    "- remove punctuation\n",
    "\n",
    "Optionally:\n",
    "- remove stopwords\n",
    "- lemmatize or stem each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbc0ffc137f5c1c48837848c7fe5ac87",
     "grade": false,
     "grade_id": "cell-8dc1d47d656679d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    # YOUR CODE STARTS HERE\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    nltk.download('stopwords')\n",
    "    nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    processed = []\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        tokens = [word for word in tokens if word not in punctuation]\n",
    "        tokens = [word for word in tokens if word not in nltk_stopwords]\n",
    "        \n",
    "        processed.append(tokens)\n",
    "    \n",
    "    return processed\n",
    "    # YOUR CODE ENDS HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/utlab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb15072be1a4a8b8b36877b02c0084b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/utlab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0b588b455f4ca1834e947c32901628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/utlab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb326938a5c243b39ccbc45eb09f12dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_reviews = preprocess(data_train.text)\n",
    "val_reviews = preprocess(data_val.text)\n",
    "test_reviews = preprocess(data_test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Transform the inputs for the model (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn's [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html?highlight=tfidf#sklearn.feature_extraction.text.TfidfVectorizer) to transform the input texts.\n",
    "\n",
    "Play with different hyperparameters.\n",
    "\n",
    "Since our texts are already preprocessed, you can use a dummy function `lambda x: x` for the `tokenizer` and `preprocessor` arguments.\n",
    "\n",
    "You can call the final variables `train_X`, `val_X`, `test_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89006a625fa5546a9601d88f59f692ef",
     "grade": false,
     "grade_id": "cell-9c89c2d098d4ba6e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x)\n",
    "# YOUR CODE STARTS HERE\n",
    "train_X = tfidf.fit_transform(train_reviews)\n",
    "val_X = tfidf.transform(val_reviews)\n",
    "test_X = tfidf.transform(test_reviews)\n",
    "# YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn's [`LabelBinarizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html?highlight=labelbinarizer#sklearn.preprocessing.LabelBinarizer) to prepare the labels.\n",
    "\n",
    "You can call the final variables `train_y`, `val_y`, `test_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3bcefec359c3cf7da8b36647bee3dc0",
     "grade": false,
     "grade_id": "cell-253ccfb3a1af3eee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lbr = LabelBinarizer()\n",
    "# YOUR CODE STARTS HERE\n",
    "train_y = lbr.fit_transform(data_train.label)\n",
    "val_y = lbr.transform(data_val.label)\n",
    "test_y = lbr.transform(data_test.label)\n",
    "# YOUR CODE ENDS HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Initialize and train the classifier (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and train a logistic regression classifier. Refer to the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression) for more details on different hyperparameters.\n",
    "\n",
    "Try to train several models with different hyperparameters and compare them with each other on the validation dataset. Use sklearn's [`classification report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification%20report#sklearn.metrics.classification_report) to get the scores with the precision of 4 digits, i.e. your score should have 4 digits after the decimal point (e.g. 0.8896)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79e5f2a5ce6446868834fec8228b62de",
     "grade": false,
     "grade_id": "cell-9ee5f21e2db2462c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: with penalty none\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8931    0.8705    0.8816      2486\n",
      "           1     0.8750    0.8970    0.8859      2514\n",
      "\n",
      "    accuracy                         0.8838      5000\n",
      "   macro avg     0.8841    0.8837    0.8838      5000\n",
      "weighted avg     0.8840    0.8838    0.8838      5000\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: with penalty l2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9053    0.8729    0.8888      2486\n",
      "           1     0.8786    0.9097    0.8939      2514\n",
      "\n",
      "    accuracy                         0.8914      5000\n",
      "   macro avg     0.8919    0.8913    0.8913      5000\n",
      "weighted avg     0.8919    0.8914    0.8914      5000\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()  # use appropriate arguments\n",
    "# YOUR CODE STARTS HERE\n",
    "model_l2 = LogisticRegression(penalty='none')\n",
    "model_l2.fit(train_X, train_y.ravel())\n",
    "y_pred = model_l2.predict(val_X)\n",
    "print('Model: with penalty none')\n",
    "print(classification_report(val_y, y_pred, digits=4))\n",
    "print('---'*20)\n",
    "\n",
    "model_none = LogisticRegression(penalty='l2')\n",
    "model_none.fit(train_X, train_y.ravel())\n",
    "y_pred = model_none.predict(val_X)\n",
    "print('Model: with penalty l2')\n",
    "print(classification_report(val_y, y_pred, digits=4))\n",
    "print('---'*20)\n",
    "# YOUR CODE ENDS HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Test the model and prepare for inference (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1949c90d864eff800c5ccd46b737665a",
     "grade": false,
     "grade_id": "cell-d0f4b083b943e360",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: with penalty none\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8932    0.8786    0.8858      2495\n",
      "           1     0.8810    0.8954    0.8881      2505\n",
      "\n",
      "    accuracy                         0.8870      5000\n",
      "   macro avg     0.8871    0.8870    0.8870      5000\n",
      "weighted avg     0.8871    0.8870    0.8870      5000\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: with penalty l2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9074    0.8878    0.8975      2495\n",
      "           1     0.8906    0.9098    0.9001      2505\n",
      "\n",
      "    accuracy                         0.8988      5000\n",
      "   macro avg     0.8990    0.8988    0.8988      5000\n",
      "weighted avg     0.8990    0.8988    0.8988      5000\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "model_l2 = LogisticRegression(penalty='none')\n",
    "model_l2.fit(train_X, train_y.ravel())\n",
    "y_pred = model_l2.predict(test_X)\n",
    "print('Model: with penalty none')\n",
    "print(classification_report(test_y, y_pred, digits=4))\n",
    "print('---'*20)\n",
    "\n",
    "model_none = LogisticRegression(penalty='l2')\n",
    "model_none.fit(train_X, train_y.ravel())\n",
    "y_pred = model_none.predict(test_X)\n",
    "print('Model: with penalty l2')\n",
    "print(classification_report(test_y, y_pred, digits=4))\n",
    "print('---'*20)\n",
    "# YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a code that would allow you to input any text into the model and get the prediction. To do that, use the same preprocessing and Tfidfvectorizer as for the training data to transform the input text for the model.\n",
    "\n",
    "Predict a label for the example text below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"\"\"\"Don't Look Up\" tells a chilling story of lies, oppression, explosion, and deceit in modern day world, but in a light hearted way. The story itself is disturbing, but the delivery is not too depressing. The numerous stars add to the entertaining factor too. I enjoyed watching it.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f2917a6ee7e33ad5fe373d03a7a32f0",
     "grade": false,
     "grade_id": "cell-24e3b269e4b3217e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/utlab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d99d3849a5421fb5b6bfe3c89cb61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30967 21037 22173 24554  7895]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "test_tokenized = preprocess(example_text)\n",
    "test_X = tfidf.transform(test_tokenized)\n",
    "\n",
    "\n",
    "def predict_label(test_X, X, k=5):\n",
    "    return np.argsort(cosine_similarity(test_X,X))[0][::-1][:k]\n",
    "\n",
    "top_pred=predict_label(test_X,train_X)\n",
    "print(top_pred)\n",
    "# YOUR CODE ENDS HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the knowledge of how a bag-of-words approach works, try to come up with four short movie reviews that would be predicted as true positive, true negative, false positive, false negative.\n",
    "\n",
    "Usually, just one or two short sentences are enough. Also, your writing skills are not assessed here, so you can write anything as long as it works! If you cannot come up with anything that meets the criteria, you can write down below why do you think it didn't work and what was your strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62975a10d2ba793398de8642a4675348",
     "grade": false,
     "grade_id": "cell-707a8813104dba43",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "\n",
    "# YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
